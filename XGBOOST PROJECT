{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad816fc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Utente\\AppData\\Local\\Temp\\ipykernel_9968\\72384789.py:113: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  group_df = group_df.replace([np.inf, -np.inf], np.nan).dropna(subset=all_features + ['log_value'])\n",
      "C:\\Users\\Utente\\AppData\\Local\\Temp\\ipykernel_9968\\72384789.py:239: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  group_test = group_test.replace([np.inf, -np.inf], np.nan).dropna(subset=selected)\n"
     ]
    }
   ],
   "source": [
    "# Football Player Market Value Prediction Model\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Data loading\n",
    "df = pd.read_csv(\"C:\\\\Users\\\\Utente\\\\Desktop\\\\BOCCONI\\\\Machine Learning\\\\ML Project\\\\Final\\\\train.csv\")\n",
    "\n",
    "# Focus on the player's main role \n",
    "df['primary_position'] = df['player_positions'].fillna('').apply(lambda x: x.split(',')[0].strip())\n",
    "\n",
    "# Convert categorical data into standardized body type classification\n",
    "df['body_type_simplified'] = df['body_type'].fillna('').apply(\n",
    "    lambda x: 'Lean' if 'Lean' in x else 'Stocky' if 'Stocky' in x else 'Normal' if 'Normal' in x else 'Other'\n",
    ")\n",
    "\n",
    "# One-hot encoded features for body type and positions\n",
    "body_dummies = pd.get_dummies(df['body_type_simplified'], prefix='body_type')\n",
    "position_dummies = pd.get_dummies(df['primary_position'], prefix='pos')\n",
    "df = pd.concat([df, body_dummies, position_dummies], axis=1)\n",
    "\n",
    "# Compute body type correlation score with market value\n",
    "bt_cols = body_dummies.columns\n",
    "bt_weights = {col: df[[col, 'value_eur']].corr().iloc[0, 1] for col in bt_cols}\n",
    "df['body_type_score'] = df[bt_cols].mul(pd.Series(bt_weights)).sum(axis=1)\n",
    "\n",
    "# Position group definitions\n",
    "group_definitions = {\n",
    "    \"fullbacks\": ['LB', 'RB', 'RWB', 'LWB'],\n",
    "    \"center_backs\": ['CB'],\n",
    "    \"midfielders\": ['CM', 'CDM'],\n",
    "    \"wingers\": ['LM', 'RM', 'RW', 'LW'],\n",
    "    \"forwards\": ['ST', 'CAM', 'CF'],\n",
    "    \"goalkeepers\": ['GK']\n",
    "}\n",
    "\n",
    "# Categorize features \n",
    "goalkeeping_features = [col for col in df.columns if col.startswith('goalkeeping_')]\n",
    "outfield_features = [col for col in df.columns if col.startswith((\n",
    "    'att_', 'def_', 'skill_', 'mentality_', 'power_', 'movement_', 'passing',\n",
    "    'shooting', 'dribbling', 'physic', 'pace', 'overall', 'potential', 'age',\n",
    "    'wage_eur', 'height_cm', 'weight_kg', 'club_team_id', 'league_level',\n",
    "    'club_jersey_number', 'club_contract_valid_until'))]\n",
    "\n",
    "# Feature selection\n",
    "# Returns a list of feature columns that meet the correlation threshold\n",
    "def select_features(df, target, feature_cols, threshold=0.05):\n",
    "    corrs = df[feature_cols + [target]].corr()[target].abs()\n",
    "    selected = corrs[corrs > threshold].index.tolist()\n",
    "    if target in selected:\n",
    "        selected.remove(target)\n",
    "    return selected\n",
    "\n",
    "\n",
    "\n",
    "# Position-Specific Model Training\n",
    "\n",
    "#Store model results for each position group\n",
    "group_results = {}\n",
    "\n",
    "for group_name, positions in group_definitions.items():\n",
    "    # print(f\"\\n Training XGBoost model for: {group_name} ({positions})\")\n",
    "    \n",
    "    # Filter for players in current position group\n",
    "    group_df = df[df['primary_position'].isin(positions)].copy()\n",
    "\n",
    "    # Apply winsorization to reduce impact of extreme outliers\n",
    "    # Cap at 99.5 percentile\n",
    "    cap = group_df['value_eur'].quantile(0.995)\n",
    "    group_df['value_eur'] = np.minimum(group_df['value_eur'], cap)\n",
    "    # print(f\"Capped value_eur at €{cap:,.0f} to reduce skew.\")\n",
    "\n",
    "    # Normalize distribution log-transforming the interested variable\n",
    "    group_df['log_value'] = np.log1p(group_df['value_eur'])\n",
    "    \n",
    "    # Interaction features\n",
    "    group_df['age_potential'] = group_df['age'] * group_df['potential']\n",
    "    group_df['value_league'] = group_df['value_eur'] * group_df['league_level']\n",
    "    group_df['bodytype_position'] = group_df['body_type_score'] * position_dummies.loc[group_df.index].sum(axis=1)\n",
    "    # Nuove feature (train)\n",
    "    # group_df['is_star'] = (group_df['overall'] >= 88).astype(int)\n",
    "    # group_df['overall_potential'] = group_df['overall'] * group_df['potential']\n",
    "    # group_df['age_inverse'] = 1 / group_df['age'].replace(0, np.nan)\n",
    "    \n",
    "    # Select base features group\n",
    "    base_features = goalkeeping_features if group_name == \"goalkeepers\" else outfield_features\n",
    "    \n",
    "    # Select interaction features\n",
    "    interaction_features = ['body_type_score', 'age_potential', 'value_league', 'bodytype_position']\n",
    "    # top players\n",
    "    # interaction_features = ['body_type_score','age_potential','value_league','bodytype_position','is_star','overall_potential','age_inverse']\n",
    "    # Add them together\n",
    "    all_features = interaction_features + base_features\n",
    "\n",
    "    # Exlude irrelevant features for each position\n",
    "    exclude_by_group = {\n",
    "        \"fullbacks\": ['shooting', 'attacking_volleys', 'attacking_heading_accuracy', 'club_jersey_number', 'skill_fk_accuracy', 'movement_agility', 'mentality_vision', 'power_jumping'] +  goalkeeping_features,\n",
    "        \"center_backs\": ['dribbling', 'skill_curve', 'attacking_crossing', 'mentality_vision'] +  goalkeeping_features,\n",
    "        \"midfielders\": ['attacking_heading_accuracy'] + goalkeeping_features,\n",
    "        \"wingers\": ['attacking_heading_accuracy', 'defending_standing_tackle'] +  goalkeeping_features,\n",
    "        \"forwards\": ['mentality_interceptions', 'defending_marking_awareness', 'defending_sliding_tackle'] +  goalkeeping_features,\n",
    "        \"goalkeepers\": outfield_features + ['goalkeeping_speed']\n",
    "    }\n",
    "\n",
    "    # Remove position-irrelevant features \n",
    "    to_exclude = exclude_by_group.get(group_name, [])\n",
    "    all_features = [f for f in all_features if f not in to_exclude]\n",
    "\n",
    "    # Handle missing values\n",
    "    group_df = group_df.replace([np.inf, -np.inf], np.nan).dropna(subset=all_features + ['log_value'])\n",
    "    selected = select_features(group_df, 'log_value', all_features, threshold=0.05)\n",
    "\n",
    "    # Define feature matrix and target value\n",
    "    X = group_df[selected]\n",
    "    y = group_df['log_value']\n",
    "\n",
    "\n",
    "    # Initialize 5-fold cross-validation \n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "    # Lists to collect performance metrics \n",
    "    fold_train_errors = []\n",
    "    fold_validation_errors = []\n",
    "    \n",
    "    # Variables to track the best model\n",
    "    best_model = None\n",
    "    best_val_rmse = float('inf')\n",
    "\n",
    "    # Train model for each cross-validation fold\n",
    "    for train_idx, val_idx in kf.split(X):\n",
    "        X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "        # Initialize XGBoost regressor \n",
    "        # These parameters are chosen to prevent overfitting and handle complexity\n",
    "        model = xgb.XGBRegressor(\n",
    "            objective='reg:squarederror',  \n",
    "            n_estimators=200,              \n",
    "            learning_rate=0.05,             \n",
    "            max_depth=4,                   \n",
    "            subsample=0.8,                  \n",
    "            colsample_bytree=0.8,           \n",
    "            random_state=42                 \n",
    "        )\n",
    "\n",
    "        # Train the model \n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Generate predictions \n",
    "        y_train_pred = model.predict(X_train)\n",
    "        y_val_pred = model.predict(X_val)\n",
    "\n",
    "        # Calculate metrics - RMSE\n",
    "        train_rmse = np.sqrt(mean_squared_error(np.expm1(y_train), np.expm1(y_train_pred)))\n",
    "        val_rmse = np.sqrt(mean_squared_error(np.expm1(y_val), np.expm1(y_val_pred)))\n",
    "        \n",
    "        # Add this fold's metrics to our running lists of all fold results\n",
    "        fold_train_errors.append(train_rmse)\n",
    "        fold_validation_errors.append(val_rmse)\n",
    "    \n",
    "        # Keep track of the best performing model\n",
    "        if val_rmse < best_val_rmse:\n",
    "            best_val_rmse = val_rmse\n",
    "            best_model = model\n",
    "            \n",
    "        # print(f\"  Fold {train_idx+1}/5 - Train RMSE: €{train_rmse:,.2f}, Val RMSE: €{val_rmse:,.2f}\")\n",
    "\n",
    "    # Calculate average performance across folds\n",
    "    avg_train_rmse = np.mean(fold_train_errors)\n",
    "    avg_val_rmse = np.mean(fold_validation_errors)\n",
    "    gap = avg_val_rmse - avg_train_rmse  # Gap indicates potential overfitting\n",
    "\n",
    "    # Print model performance summary\n",
    "    # print(f\"{group_name.capitalize()} - Train RMSE: €{avg_train_rmse:,.2f}, Validation RMSE: €{avg_val_rmse:,.2f}, Gap: €{gap:,.2f}\")\n",
    "\n",
    "    group_results[group_name] = {\n",
    "        \"model\": best_model,\n",
    "        \"train_rmse\": avg_train_rmse,\n",
    "        \"val_rmse\": avg_val_rmse,\n",
    "        \"gap\": gap,\n",
    "        \"features\": selected\n",
    "    }\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Test Set Prediction\n",
    "# -----------------------------------------------------------------------------\n",
    " \n",
    "# Load test dataset and prepare submission template\n",
    "test_df = pd.read_csv(\"C:\\\\Users\\\\Utente\\\\Desktop\\\\BOCCONI\\\\Machine Learning\\\\ML Project\\\\Final\\\\test.csv\")\n",
    "submission_df = pd.read_csv(\"C:\\\\Users\\\\Utente\\\\Desktop\\\\BOCCONI\\\\Machine Learning\\\\ML Project\\\\Final\\\\submission.csv\")\n",
    "\n",
    "# Apply the same preprocessing steps used for training data\n",
    "test_df['primary_position'] = test_df['player_positions'].fillna('').apply(lambda x: x.split(',')[0].strip())\n",
    "test_df['body_type_simplified'] = test_df['body_type'].fillna('').apply(\n",
    "    lambda x: 'Lean' if 'Lean' in x else 'Stocky' if 'Stocky' in x else 'Normal' if 'Normal' in x else 'Other'\n",
    ")\n",
    "\n",
    "# Create one-hot encoded features\n",
    "body_dummies = pd.get_dummies(test_df['body_type_simplified'], prefix='body_type')\n",
    "position_dummies = pd.get_dummies(test_df['primary_position'], prefix='pos')\n",
    "test_df = pd.concat([test_df, body_dummies, position_dummies], axis=1)\n",
    "\n",
    "# Get all body type and position columns from training data\n",
    "train_body_cols = [col for col in df.columns if col.startswith('body_type_')]\n",
    "train_pos_cols = [col for col in df.columns if col.startswith('pos_')]\n",
    "\n",
    "# Apply body type scoring using weights \n",
    "bt_cols = body_dummies.columns\n",
    "bt_weights = {col: df[[col, 'value_eur']].corr().iloc[0, 1] for col in bt_cols if col in df.columns}\n",
    "test_df['body_type_score'] = test_df[bt_cols].mul(pd.Series(bt_weights)).sum(axis=1)\n",
    "\n",
    "# List to store predictions for each position group\n",
    "predictions = []\n",
    "\n",
    "# Generate predictions for each position group\n",
    "for group_name, positions in group_definitions.items():\n",
    "\n",
    "    # Retrieve trained model and selected features for this position group\n",
    "    model = group_results[group_name][\"model\"]\n",
    "    selected = group_results[group_name][\"features\"]\n",
    "\n",
    "    # include players in current position group\n",
    "    group_test = test_df[test_df['primary_position'].isin(positions)].copy()\n",
    "\n",
    "    # Create the same interaction features used during training\n",
    "    group_test['age_potential'] = group_test['age'] * group_test['potential']\n",
    "    group_test['value_league'] = group_test['league_level']\n",
    "    group_test['bodytype_position'] = group_test['body_type_score'] * position_dummies.loc[group_test.index].sum(axis=1)\n",
    "    \n",
    "    # Additional features (commented out to match training configuration)\n",
    "    # group_test['is_star'] = (group_test['overall'] >= 88).astype(int)\n",
    "    # group_test['overall_potential'] = group_test['overall'] * group_test['potential']\n",
    "    # group_test['age_inverse'] = 1 / group_test['age'].replace(0, np.nan)\n",
    "\n",
    "    # Handle missing values and prepare feature matrix\n",
    "    group_test = group_test.replace([np.inf, -np.inf], np.nan).dropna(subset=selected)\n",
    "    X_test = group_test[selected]\n",
    "\n",
    "    # Generate predictions and transform back from log scale\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred = np.expm1(y_pred)  \n",
    "\n",
    "    # Create dataframe with predictions\n",
    "    result_df = pd.DataFrame({\n",
    "        'index': group_test['Unnamed: 0'],  # Preserve original index for final sorting\n",
    "        'value_eur': y_pred.round().astype(float)  # Round to nearest integer value\n",
    "    })\n",
    "\n",
    "    # Add to collection of predictions\n",
    "    predictions.append(result_df)\n",
    "\n",
    "# Final submission\n",
    "\n",
    "# Combine predictions \n",
    "final_submission = pd.concat(predictions, ignore_index=True)\n",
    "\n",
    "# Sort by original index \n",
    "final_submission = final_submission.sort_values(by=\"index\").reset_index(drop=True)\n",
    "\n",
    "# Save to CSV file \n",
    "final_submission[['value_eur']].to_csv(\n",
    "    \"C:\\\\Users\\\\Utente\\\\Desktop\\\\BOCCONI\\\\Machine Learning\\\\ML Project\\\\Final\\\\submission.csv\",\n",
    "    index=True\n",
    ")\n",
    "\n",
    "\n",
    "# # Visualize feature importance for each position group model\n",
    "# for group_name, result in group_results.items():\n",
    "#     model = result[\"model\"]\n",
    "#     feature_names = result[\"features\"]\n",
    "#\n",
    "#     # Extract feature importance scores (gain metric)\n",
    "#     importance_dict = model.get_booster().get_score(importance_type='gain')\n",
    "#     importance_df = pd.DataFrame.from_dict(importance_dict, orient='index', columns=['gain'])\n",
    "#     importance_df.index.name = 'feature'\n",
    "#     importance_df.reset_index(inplace=True)\n",
    "#\n",
    "#     # Filter to show only low-importance features\n",
    "#     low_importance_df = importance_df[importance_df['gain'] <= 0.02].sort_values(by='gain')\n",
    "#\n",
    "#     if low_importance_df.empty:\n",
    "#         print(f\"\\n No low-importance features (≤ 0.02 gain) for {group_name}.\")\n",
    "#         continue\n",
    "#\n",
    "#     # Visualize low-importance features\n",
    "#     print(f\"\\n Low-importance features for {group_name.capitalize()}\")\n",
    "#     plt.figure(figsize=(8, max(4, len(low_importance_df) * 0.5)))\n",
    "#     plt.barh(low_importance_df['feature'], low_importance_df['gain'], color='skyblue')\n",
    "#     plt.xlabel(\"Gain (Importance)\")\n",
    "#     plt.title(f\"{group_name.capitalize()} - Low Importance Features (≤ 0.02)\")\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
